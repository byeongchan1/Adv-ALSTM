{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.8 64-bit ('venv36': virtualenv)"
    },
    "interpreter": {
      "hash": "0867f69e5b16c2da0a94f2a308042fc4e0db7f5095985c82e39af55064218631"
    },
    "colab": {
      "name": "practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byeongchan1/Adv-ALSTM/blob/master/practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMNxe7HrUVLo"
      },
      "source": [
        "# 0. 모듈 import 및 cwd 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbZO5SGdnibi",
        "outputId": "8ce9c896-0603-4197-c304-11c17182dd98"
      },
      "source": [
        "# 모듈 import\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/MyDrive/python/python_dong/data_axis_transform1')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBRQBuEynibj"
      },
      "source": [
        "#1. 데이터 전처리 과정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a04iuaJnibl"
      },
      "source": [
        "# data path 지정\n",
        "raw_data_path = './Adv-ALSTM/data/stocknet-dataset/price/raw'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETvEen20nibl"
      },
      "source": [
        "if 'stocknet' in raw_data_path:\n",
        "    tra_date = '2014-01-02'\n",
        "    val_date = '2015-08-03'\n",
        "    tes_date = '2015-10-01'\n",
        "    end_date = '2015-12-31'\n",
        "elif 'kdd17' in raw_data_path:\n",
        "    tra_date = '2007-01-03'\n",
        "    val_date = '2015-01-02'\n",
        "    tes_date = '2016-01-04'\n",
        "    end_date = '2016-12-31'\n",
        "else:\n",
        "    print('unexpected path: %s' % raw_data_path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HzxX-canibl",
        "outputId": "f7f5c7d9-d0ca-4570-d59c-b39d1bddda35"
      },
      "source": [
        "print(tra_date, val_date, tes_date, end_date)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2014-01-02 2015-08-03 2015-10-01 2015-12-31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-2KOc0Wnibm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c3e128-3246-4ec0-8919-d2520bb03928"
      },
      "source": [
        "# os.path.isfile : 파일이 있는지 없는 지 체크\n",
        "# os.path.join(data_path, fname) : 폴더 디렉터리와 fname(stockname.csv) 붙임\n",
        "fnames = [fname for fname in os.listdir(raw_data_path) if\n",
        "            os.path.isfile(os.path.join(raw_data_path,fname))]\n",
        "fnames"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SPLP.csv',\n",
              " 'CELG.csv',\n",
              " 'WFC.csv',\n",
              " 'INTC.csv',\n",
              " 'JNJ.csv',\n",
              " 'AAPL.csv',\n",
              " 'GOOG.csv',\n",
              " 'BP.csv',\n",
              " 'GE.csv',\n",
              " 'BABA.csv',\n",
              " 'PTR.csv',\n",
              " 'AMZN.csv',\n",
              " 'SLB.csv',\n",
              " 'SRE.csv',\n",
              " 'KO.csv',\n",
              " 'UTX.csv',\n",
              " 'BHP.csv',\n",
              " 'BRK-A.csv',\n",
              " 'NEE.csv',\n",
              " 'DHR.csv',\n",
              " 'BBL.csv',\n",
              " 'CVX.csv',\n",
              " 'NVS.csv',\n",
              " 'CAT.csv',\n",
              " 'PICO.csv',\n",
              " 'VZ.csv',\n",
              " 'AEP.csv',\n",
              " 'T.csv',\n",
              " 'HD.csv',\n",
              " 'PG.csv',\n",
              " 'BCH.csv',\n",
              " 'WMT.csv',\n",
              " 'SNY.csv',\n",
              " 'HSBC.csv',\n",
              " 'AMGN.csv',\n",
              " 'UPS.csv',\n",
              " 'NGG.csv',\n",
              " 'BA.csv',\n",
              " 'MA.csv',\n",
              " 'IEP.csv',\n",
              " 'XOM.csv',\n",
              " 'BSAC.csv',\n",
              " 'DIS.csv',\n",
              " 'BUD.csv',\n",
              " 'PPL.csv',\n",
              " 'ABB.csv',\n",
              " 'CHL.csv',\n",
              " 'AGFS.csv',\n",
              " 'SO.csv',\n",
              " 'GD.csv',\n",
              " 'TSM.csv',\n",
              " 'PM.csv',\n",
              " 'FB.csv',\n",
              " 'DUK.csv',\n",
              " 'CHTR.csv',\n",
              " 'MO.csv',\n",
              " 'PFE.csv',\n",
              " 'MSFT.csv',\n",
              " 'D.csv',\n",
              " 'HON.csv',\n",
              " 'UNH.csv',\n",
              " 'TOT.csv',\n",
              " 'UN.csv',\n",
              " 'V.csv',\n",
              " 'HRG.csv',\n",
              " 'EXC.csv',\n",
              " 'CSCO.csv',\n",
              " 'LMT.csv',\n",
              " 'MCD.csv',\n",
              " 'BAC.csv',\n",
              " 'RDS-B.csv',\n",
              " 'PCG.csv',\n",
              " 'UL.csv',\n",
              " 'C.csv',\n",
              " 'CODI.csv',\n",
              " 'SNP.csv',\n",
              " 'ORCL.csv',\n",
              " 'PEP.csv',\n",
              " 'PCLN.csv',\n",
              " 'MDT.csv',\n",
              " 'TM.csv',\n",
              " 'ABBV.csv',\n",
              " 'MMM.csv',\n",
              " 'JPM.csv',\n",
              " 'REX.csv',\n",
              " 'CMCSA.csv',\n",
              " 'MRK.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tNc2Zw6UvmV"
      },
      "source": [
        "fname = fnames[0]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I7f66Tjnibn"
      },
      "source": [
        "df = pd.read_csv(os.path.join(raw_data_path,fname))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcz3Hm3znibo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7711d95a-13c4-489b-925e-f7a8f5117677"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-09-04</td>\n",
              "      <td>10.98</td>\n",
              "      <td>11.08</td>\n",
              "      <td>10.98</td>\n",
              "      <td>10.98</td>\n",
              "      <td>10.874151</td>\n",
              "      <td>7400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-09-05</td>\n",
              "      <td>10.98</td>\n",
              "      <td>10.99</td>\n",
              "      <td>10.95</td>\n",
              "      <td>10.99</td>\n",
              "      <td>10.884055</td>\n",
              "      <td>22600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-09-06</td>\n",
              "      <td>11.00</td>\n",
              "      <td>11.10</td>\n",
              "      <td>10.92</td>\n",
              "      <td>10.93</td>\n",
              "      <td>10.824634</td>\n",
              "      <td>23600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-09-07</td>\n",
              "      <td>11.00</td>\n",
              "      <td>11.00</td>\n",
              "      <td>10.95</td>\n",
              "      <td>10.98</td>\n",
              "      <td>10.874151</td>\n",
              "      <td>88500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-09-10</td>\n",
              "      <td>10.96</td>\n",
              "      <td>11.06</td>\n",
              "      <td>10.96</td>\n",
              "      <td>10.99</td>\n",
              "      <td>10.884055</td>\n",
              "      <td>87000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date   Open   High    Low  Close  Adj Close  Volume\n",
              "0  2012-09-04  10.98  11.08  10.98  10.98  10.874151    7400\n",
              "1  2012-09-05  10.98  10.99  10.95  10.99  10.884055   22600\n",
              "2  2012-09-06  11.00  11.10  10.92  10.93  10.824634   23600\n",
              "3  2012-09-07  11.00  11.00  10.95  10.98  10.874151   88500\n",
              "4  2012-09-10  10.96  11.06  10.96  10.99  10.884055   87000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ6au69Wnibo"
      },
      "source": [
        "COLUMNS_FEATURE_DATA_V1 = ['open_close_ratio', 'high_close_ratio', \n",
        "                           'low_close_ratio', 'close_lastclose_ratio', \n",
        "                           'adjclose_lastadjclose_ratio', 'close_ma5_ratio', \n",
        "                           'close_ma10_ratio', 'close_ma15_ratio', 'close_ma20_ratio', \n",
        "                           'close_ma25_ratio', 'close_ma30_ratio']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQMArajSnibo"
      },
      "source": [
        "ver = 'v1' # ver in ['v1', 'v2']\n",
        "if ver == 'v1':\n",
        "    COLUMNS_FEATURE = COLUMNS_FEATURE_DATA_V1\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXgUBjGhnibo"
      },
      "source": [
        "windows = [5,10,15,20,25,30]\n",
        "\n",
        "def preprocess(df, windows):\n",
        "   '''\n",
        "   전처리 함수 역할 : 전체 feature생성하여 df column에 추가\n",
        "   '''\n",
        "   data = df\n",
        "   data['open_close_ratio'] = data['Open'] / data['Close'] - 1\n",
        "   data['high_close_ratio'] = data['High'] / data['Close'] - 1\n",
        "   data['low_close_ratio'] = data['Low'] / data['Close'] - 1\n",
        "\n",
        "   data['close_lastclose_ratio'] = np.zeros(len(data))\n",
        "   data.loc[1:, 'close_lastclose_ratio'] = data['Close'][1:].values / data['Close'][:-1].values - 1\n",
        "\n",
        "   data['adjclose_lastadjclose_ratio'] = np.zeros(len(data))\n",
        "   data.loc[1:, 'adjclose_lastadjclose_ratio'] = data['Adj Close'][1:].values / data['Adj Close'][:-1].values - 1\n",
        "\n",
        "   for window in windows:\n",
        "      data[f'close_ma{window}_ratio'] = data['Adj Close'].rolling(window).mean()/data['Adj Close'] - 1\n",
        "   \n",
        "   data['label'] = np.append((data['Close'][1:].values > data['Close'][:-1].values)*1,0)\n",
        "\n",
        "   return data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUBsJ5Ornibp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "59ab580c-362d-462a-df5f-45ec5020e7fa"
      },
      "source": [
        "df = preprocess(df, windows)\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>open_close_ratio</th>\n",
              "      <th>high_close_ratio</th>\n",
              "      <th>low_close_ratio</th>\n",
              "      <th>close_lastclose_ratio</th>\n",
              "      <th>adjclose_lastadjclose_ratio</th>\n",
              "      <th>close_ma5_ratio</th>\n",
              "      <th>close_ma10_ratio</th>\n",
              "      <th>close_ma15_ratio</th>\n",
              "      <th>close_ma20_ratio</th>\n",
              "      <th>close_ma25_ratio</th>\n",
              "      <th>close_ma30_ratio</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-09-04</td>\n",
              "      <td>10.98</td>\n",
              "      <td>11.08</td>\n",
              "      <td>10.98</td>\n",
              "      <td>10.98</td>\n",
              "      <td>10.874151</td>\n",
              "      <td>7400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-09-05</td>\n",
              "      <td>10.98</td>\n",
              "      <td>10.99</td>\n",
              "      <td>10.95</td>\n",
              "      <td>10.99</td>\n",
              "      <td>10.884055</td>\n",
              "      <td>22600</td>\n",
              "      <td>-0.000910</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.003640</td>\n",
              "      <td>0.000911</td>\n",
              "      <td>0.000911</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-09-06</td>\n",
              "      <td>11.00</td>\n",
              "      <td>11.10</td>\n",
              "      <td>10.92</td>\n",
              "      <td>10.93</td>\n",
              "      <td>10.824634</td>\n",
              "      <td>23600</td>\n",
              "      <td>0.006404</td>\n",
              "      <td>0.015554</td>\n",
              "      <td>-0.000915</td>\n",
              "      <td>-0.005460</td>\n",
              "      <td>-0.005459</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-09-07</td>\n",
              "      <td>11.00</td>\n",
              "      <td>11.00</td>\n",
              "      <td>10.95</td>\n",
              "      <td>10.98</td>\n",
              "      <td>10.874151</td>\n",
              "      <td>88500</td>\n",
              "      <td>0.001821</td>\n",
              "      <td>0.001821</td>\n",
              "      <td>-0.002732</td>\n",
              "      <td>0.004575</td>\n",
              "      <td>0.004574</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-09-10</td>\n",
              "      <td>10.96</td>\n",
              "      <td>11.06</td>\n",
              "      <td>10.96</td>\n",
              "      <td>10.99</td>\n",
              "      <td>10.884055</td>\n",
              "      <td>87000</td>\n",
              "      <td>-0.002730</td>\n",
              "      <td>0.006369</td>\n",
              "      <td>-0.002730</td>\n",
              "      <td>0.000911</td>\n",
              "      <td>0.000911</td>\n",
              "      <td>-0.001456</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date   Open   High  ...  close_ma25_ratio  close_ma30_ratio  label\n",
              "0  2012-09-04  10.98  11.08  ...               NaN               NaN      1\n",
              "1  2012-09-05  10.98  10.99  ...               NaN               NaN      0\n",
              "2  2012-09-06  11.00  11.10  ...               NaN               NaN      1\n",
              "3  2012-09-07  11.00  11.00  ...               NaN               NaN      1\n",
              "4  2012-09-10  10.96  11.06  ...               NaN               NaN      1\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5cwoZL-nibp"
      },
      "source": [
        "data = df"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec-kOxtvnibp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "95863dc6-1157-4fd8-e422-fa4e13ac07f8"
      },
      "source": [
        "data.tail()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>open_close_ratio</th>\n",
              "      <th>high_close_ratio</th>\n",
              "      <th>low_close_ratio</th>\n",
              "      <th>close_lastclose_ratio</th>\n",
              "      <th>adjclose_lastadjclose_ratio</th>\n",
              "      <th>close_ma5_ratio</th>\n",
              "      <th>close_ma10_ratio</th>\n",
              "      <th>close_ma15_ratio</th>\n",
              "      <th>close_ma20_ratio</th>\n",
              "      <th>close_ma25_ratio</th>\n",
              "      <th>close_ma30_ratio</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>2017-08-28</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>18.450001</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>18.40</td>\n",
              "      <td>18.40</td>\n",
              "      <td>7000</td>\n",
              "      <td>-0.021739</td>\n",
              "      <td>0.002717</td>\n",
              "      <td>-0.021739</td>\n",
              "      <td>0.016575</td>\n",
              "      <td>0.016575</td>\n",
              "      <td>-0.013587</td>\n",
              "      <td>-0.006359</td>\n",
              "      <td>-0.002246</td>\n",
              "      <td>-0.000870</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.001812</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>2017-08-29</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>18.40</td>\n",
              "      <td>18.40</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.011957</td>\n",
              "      <td>-0.007174</td>\n",
              "      <td>-0.002246</td>\n",
              "      <td>-0.001141</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.001630</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>2017-08-30</td>\n",
              "      <td>18.150000</td>\n",
              "      <td>18.150000</td>\n",
              "      <td>18.150000</td>\n",
              "      <td>18.15</td>\n",
              "      <td>18.15</td>\n",
              "      <td>700</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.013587</td>\n",
              "      <td>-0.013587</td>\n",
              "      <td>0.002755</td>\n",
              "      <td>0.004518</td>\n",
              "      <td>0.009881</td>\n",
              "      <td>0.011653</td>\n",
              "      <td>0.013399</td>\n",
              "      <td>0.014747</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>2017-08-31</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>18.250000</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>18.15</td>\n",
              "      <td>18.15</td>\n",
              "      <td>500</td>\n",
              "      <td>-0.002755</td>\n",
              "      <td>0.005510</td>\n",
              "      <td>-0.002755</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004959</td>\n",
              "      <td>0.003140</td>\n",
              "      <td>0.008595</td>\n",
              "      <td>0.010964</td>\n",
              "      <td>0.012408</td>\n",
              "      <td>0.014105</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>2017-09-01</td>\n",
              "      <td>18.049999</td>\n",
              "      <td>18.129999</td>\n",
              "      <td>18.049999</td>\n",
              "      <td>18.08</td>\n",
              "      <td>18.08</td>\n",
              "      <td>700</td>\n",
              "      <td>-0.001659</td>\n",
              "      <td>0.002765</td>\n",
              "      <td>-0.001659</td>\n",
              "      <td>-0.003857</td>\n",
              "      <td>-0.003857</td>\n",
              "      <td>0.008628</td>\n",
              "      <td>0.005808</td>\n",
              "      <td>0.010914</td>\n",
              "      <td>0.014132</td>\n",
              "      <td>0.015398</td>\n",
              "      <td>0.017072</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date       Open  ...  close_ma30_ratio  label\n",
              "1253  2017-08-28  18.000000  ...          0.001812      0\n",
              "1254  2017-08-29  18.400000  ...          0.001630      0\n",
              "1255  2017-08-30  18.150000  ...          0.014747      0\n",
              "1256  2017-08-31  18.100000  ...          0.014105      0\n",
              "1257  2017-09-01  18.049999  ...          0.017072      0\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzAqR2MRnibp"
      },
      "source": [
        "# feature 추가한 csv 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paTqbAQPnibq"
      },
      "source": [
        "feature_data_path = './Adv-ALSTM/data/stocknet-dataset/price/feature'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Zv-V4Unibq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ba9a46-1a19-4f19-f632-8bd473193684"
      },
      "source": [
        "fname = fnames[0]\n",
        "os.path.isfile(os.path.join(feature_data_path,fname))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98F1KCv2nibq"
      },
      "source": [
        "for fname in fnames:\n",
        "   if not os.path.isfile(os.path.join(feature_data_path,fname)):\n",
        "      df_raw = pd.read_csv(os.path.join(raw_data_path,fname))\n",
        "      data = preprocess(df_raw, windows)\n",
        "\n",
        "      # 폴더 없으면 생성\n",
        "      try:\n",
        "         if not os.path.exists(feature_data_path):\n",
        "            os.makedirs(feature_data_path)\n",
        "      except OSError:\n",
        "         print ('Error: Creating directory. ' +  feature_data_path)\n",
        "\n",
        "      #csv 파일 저장\n",
        "      data.to_csv(os.path.join(feature_data_path,fname))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DJdL45Znibq"
      },
      "source": [
        "# train, validation, test data 나누기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO4H6WaHnibr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a9c1aed-88fd-425b-84e5-918300b74e23"
      },
      "source": [
        "print(tra_date, val_date, tes_date, end_date)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2014-01-02 2015-08-03 2015-10-01 2015-12-31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8fDqmnFnibr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "6d7f2272-8d00-4ea1-96fe-fc619797166e"
      },
      "source": [
        "# learning_data = data[(data['Date'] >= tra_date) & (data['Date'] <= end_date)]\n",
        "tra_data_X = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)][COLUMNS_FEATURE]\n",
        "tra_data_Y = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)]['label']\n",
        "\n",
        "val_data_X = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)][COLUMNS_FEATURE]\n",
        "val_data_Y = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)]['label']\n",
        "\n",
        "test_data_X = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)][COLUMNS_FEATURE]\n",
        "test_data_Y = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)]['label']\n",
        "\n",
        "\n",
        "tra_data_X.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open_close_ratio</th>\n",
              "      <th>high_close_ratio</th>\n",
              "      <th>low_close_ratio</th>\n",
              "      <th>close_lastclose_ratio</th>\n",
              "      <th>adjclose_lastadjclose_ratio</th>\n",
              "      <th>close_ma5_ratio</th>\n",
              "      <th>close_ma10_ratio</th>\n",
              "      <th>close_ma15_ratio</th>\n",
              "      <th>close_ma20_ratio</th>\n",
              "      <th>close_ma25_ratio</th>\n",
              "      <th>close_ma30_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>-0.015367</td>\n",
              "      <td>0.002846</td>\n",
              "      <td>-0.015367</td>\n",
              "      <td>0.012680</td>\n",
              "      <td>0.012680</td>\n",
              "      <td>-0.007513</td>\n",
              "      <td>-0.005521</td>\n",
              "      <td>-0.008234</td>\n",
              "      <td>-0.010074</td>\n",
              "      <td>-0.011793</td>\n",
              "      <td>-0.022387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>0.003429</td>\n",
              "      <td>0.003429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.003984</td>\n",
              "      <td>-0.003984</td>\n",
              "      <td>-0.004571</td>\n",
              "      <td>-0.001714</td>\n",
              "      <td>-0.003429</td>\n",
              "      <td>-0.005286</td>\n",
              "      <td>-0.007291</td>\n",
              "      <td>-0.015276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>-0.005780</td>\n",
              "      <td>0.001156</td>\n",
              "      <td>-0.008092</td>\n",
              "      <td>-0.011429</td>\n",
              "      <td>-0.011429</td>\n",
              "      <td>0.006012</td>\n",
              "      <td>0.008671</td>\n",
              "      <td>0.008324</td>\n",
              "      <td>0.006098</td>\n",
              "      <td>0.004092</td>\n",
              "      <td>-0.001522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006012</td>\n",
              "      <td>0.006936</td>\n",
              "      <td>0.008131</td>\n",
              "      <td>0.006069</td>\n",
              "      <td>0.004509</td>\n",
              "      <td>0.000983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>0.000578</td>\n",
              "      <td>0.000578</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005434</td>\n",
              "      <td>0.006590</td>\n",
              "      <td>0.007746</td>\n",
              "      <td>0.006040</td>\n",
              "      <td>0.004555</td>\n",
              "      <td>0.002832</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     open_close_ratio  high_close_ratio  ...  close_ma25_ratio  close_ma30_ratio\n",
              "333         -0.015367          0.002846  ...         -0.011793         -0.022387\n",
              "334          0.003429          0.003429  ...         -0.007291         -0.015276\n",
              "335         -0.005780          0.001156  ...          0.004092         -0.001522\n",
              "336          0.000000          0.000000  ...          0.004509          0.000983\n",
              "337          0.000578          0.000578  ...          0.004555          0.002832\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbEMU6SEnibr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "eb09c135-401f-441f-c11b-5c8825317856"
      },
      "source": [
        "test_data_X.tail()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open_close_ratio</th>\n",
              "      <th>high_close_ratio</th>\n",
              "      <th>low_close_ratio</th>\n",
              "      <th>close_lastclose_ratio</th>\n",
              "      <th>adjclose_lastadjclose_ratio</th>\n",
              "      <th>close_ma5_ratio</th>\n",
              "      <th>close_ma10_ratio</th>\n",
              "      <th>close_ma15_ratio</th>\n",
              "      <th>close_ma20_ratio</th>\n",
              "      <th>close_ma25_ratio</th>\n",
              "      <th>close_ma30_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>832</th>\n",
              "      <td>0.007898</td>\n",
              "      <td>0.007898</td>\n",
              "      <td>-0.003645</td>\n",
              "      <td>-0.003632</td>\n",
              "      <td>-0.003632</td>\n",
              "      <td>0.012394</td>\n",
              "      <td>0.003159</td>\n",
              "      <td>0.009761</td>\n",
              "      <td>0.016403</td>\n",
              "      <td>0.020462</td>\n",
              "      <td>0.022965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833</th>\n",
              "      <td>0.005505</td>\n",
              "      <td>0.005505</td>\n",
              "      <td>-0.006116</td>\n",
              "      <td>-0.006683</td>\n",
              "      <td>-0.006683</td>\n",
              "      <td>0.010520</td>\n",
              "      <td>0.009847</td>\n",
              "      <td>0.013619</td>\n",
              "      <td>0.020856</td>\n",
              "      <td>0.025615</td>\n",
              "      <td>0.028094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834</th>\n",
              "      <td>0.001833</td>\n",
              "      <td>0.003054</td>\n",
              "      <td>-0.001222</td>\n",
              "      <td>0.001223</td>\n",
              "      <td>0.001223</td>\n",
              "      <td>0.004765</td>\n",
              "      <td>0.009957</td>\n",
              "      <td>0.009733</td>\n",
              "      <td>0.017654</td>\n",
              "      <td>0.022798</td>\n",
              "      <td>0.025779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>0.004287</td>\n",
              "      <td>0.004287</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.002444</td>\n",
              "      <td>-0.002444</td>\n",
              "      <td>0.004654</td>\n",
              "      <td>0.013288</td>\n",
              "      <td>0.010165</td>\n",
              "      <td>0.017942</td>\n",
              "      <td>0.023368</td>\n",
              "      <td>0.026842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>836</th>\n",
              "      <td>-0.001831</td>\n",
              "      <td>0.003053</td>\n",
              "      <td>-0.001831</td>\n",
              "      <td>0.003062</td>\n",
              "      <td>0.003062</td>\n",
              "      <td>-0.000122</td>\n",
              "      <td>0.011539</td>\n",
              "      <td>0.005779</td>\n",
              "      <td>0.012637</td>\n",
              "      <td>0.018803</td>\n",
              "      <td>0.022405</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     open_close_ratio  high_close_ratio  ...  close_ma25_ratio  close_ma30_ratio\n",
              "832          0.007898          0.007898  ...          0.020462          0.022965\n",
              "833          0.005505          0.005505  ...          0.025615          0.028094\n",
              "834          0.001833          0.003054  ...          0.022798          0.025779\n",
              "835          0.004287          0.004287  ...          0.023368          0.026842\n",
              "836         -0.001831          0.003053  ...          0.018803          0.022405\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4Dk7i7HcZh4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8Nx3KOOlIt_"
      },
      "source": [
        "# Feature Transformation Layer 만들어야합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOyMFbczciAy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rck-OFU0Kaov"
      },
      "source": [
        "## 1. input data 3차원으로 쌓기\n",
        "shape = (stock 종류수, date, feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7rrJSVjZeQX"
      },
      "source": [
        "요건\n",
        "1. 모든 티커 데이터의 date가 맞는지?\n",
        "2. 결측치는 없는지?\n",
        "3. 티커와 데이터 메치 가능해야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqoDX-DRKZ9J",
        "outputId": "22281371-c097-4912-a4ec-fa36e88d54d3"
      },
      "source": [
        "raw_data_path = './Adv-ALSTM/data/stocknet-dataset/price/raw'\n",
        "\n",
        "\n",
        "tra_data_X = []\n",
        "tra_data_Y = []\n",
        "val_data_X = []\n",
        "val_data_Y = []\n",
        "test_data_X = []\n",
        "test_data_Y = []\n",
        "tickers = []\n",
        "\n",
        "cnt = 0\n",
        "fail_cnt = 0\n",
        "\n",
        "fnames = [fname for fname in os.listdir(raw_data_path) if\n",
        "            os.path.isfile(os.path.join(raw_data_path,fname))]\n",
        "\n",
        "for fname in fnames:\n",
        "\n",
        "    df = pd.read_csv(os.path.join(raw_data_path,fname))\n",
        "    data = preprocess(df, windows)\n",
        "\n",
        "    learning_data = data[(data['Date'] >= tra_date) & (data['Date'] <= end_date)]['Date']\n",
        "    tra_data_X_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)][COLUMNS_FEATURE]\n",
        "    tra_data_Y_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)]['label']\n",
        "\n",
        "    val_data_X_ticker = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)][COLUMNS_FEATURE]\n",
        "    val_data_Y_ticker = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)]['label']\n",
        "\n",
        "    test_data_X_ticker = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)][COLUMNS_FEATURE]\n",
        "    test_data_Y_ticker = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)]['label']\n",
        "\n",
        "\n",
        "    if cnt == 0:\n",
        "        target_dates = learning_data\n",
        "    \n",
        "    print('ticker : {}, date check : {}'.format(fname, np.array_equal(target_dates.values, learning_data.values)))\n",
        "    if np.array_equal(target_dates.values, learning_data.values): \n",
        "        \n",
        "        tra_data_X.append(tra_data_X_ticker.values)\n",
        "        tra_data_Y.append(tra_data_Y_ticker.values)\n",
        "\n",
        "        val_data_X.append(val_data_X_ticker.values)\n",
        "        val_data_Y.append(val_data_Y_ticker.values)\n",
        "        \n",
        "        test_data_X.append(test_data_X_ticker.values)\n",
        "        test_data_Y.append(test_data_Y_ticker.values)\n",
        "\n",
        "        tickers.append(fname)\n",
        "    else : \n",
        "        fail_cnt += 1\n",
        "    \n",
        "    cnt += 1\n",
        "\n",
        "print(cnt, len(fnames))\n",
        "print('fail_cnt :', fail_cnt)\n",
        "\n",
        "# 마지막에 index 종목 넣기\n",
        "raw_data_index_path = './Adv-ALSTM/data/stocknet-dataset/price/raw/index'\n",
        "\n",
        "fname = os.listdir(raw_data_index_path)[0]\n",
        "\n",
        "df = pd.read_csv(os.path.join(raw_data_index_path,fname))\n",
        "data = preprocess(df, windows)\n",
        "\n",
        "learning_data = data[(data['Date'] >= tra_date) & (data['Date'] <= end_date)]['Date']\n",
        "tra_data_X_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)][COLUMNS_FEATURE]\n",
        "tra_data_Y_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)]['label']\n",
        "\n",
        "val_data_X_ticker = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)][COLUMNS_FEATURE]\n",
        "val_data_Y_ticker = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)]['label']\n",
        "\n",
        "test_data_X_ticker = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)][COLUMNS_FEATURE]\n",
        "test_data_Y_ticker = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)]['label']\n",
        "\n",
        "print('ticker : {}, date check : {}'.format(fname, np.array_equal(target_dates.values, learning_data.values)))\n",
        "if np.array_equal(target_dates.values, learning_data.values):\n",
        "    \n",
        "    tra_data_X.append(tra_data_X_ticker.values)\n",
        "    tra_data_Y.append(tra_data_Y_ticker.values)\n",
        "\n",
        "    val_data_X.append(val_data_X_ticker.values)\n",
        "    val_data_Y.append(val_data_Y_ticker.values)\n",
        "    \n",
        "    test_data_X.append(test_data_X_ticker.values)\n",
        "    test_data_Y.append(test_data_Y_ticker.values)\n",
        "\n",
        "    tickers.append(fname)\n",
        "\n",
        "# tra_data_X"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ticker : SPLP.csv, date check : True\n",
            "ticker : CELG.csv, date check : True\n",
            "ticker : WFC.csv, date check : True\n",
            "ticker : INTC.csv, date check : True\n",
            "ticker : JNJ.csv, date check : True\n",
            "ticker : AAPL.csv, date check : True\n",
            "ticker : GOOG.csv, date check : True\n",
            "ticker : BP.csv, date check : True\n",
            "ticker : GE.csv, date check : True\n",
            "ticker : BABA.csv, date check : False\n",
            "ticker : PTR.csv, date check : True\n",
            "ticker : AMZN.csv, date check : True\n",
            "ticker : SLB.csv, date check : True\n",
            "ticker : SRE.csv, date check : True\n",
            "ticker : KO.csv, date check : True\n",
            "ticker : UTX.csv, date check : True\n",
            "ticker : BHP.csv, date check : True\n",
            "ticker : BRK-A.csv, date check : True\n",
            "ticker : NEE.csv, date check : True\n",
            "ticker : DHR.csv, date check : True\n",
            "ticker : BBL.csv, date check : True\n",
            "ticker : CVX.csv, date check : True\n",
            "ticker : NVS.csv, date check : True\n",
            "ticker : CAT.csv, date check : True\n",
            "ticker : PICO.csv, date check : True\n",
            "ticker : VZ.csv, date check : True\n",
            "ticker : AEP.csv, date check : True\n",
            "ticker : T.csv, date check : True\n",
            "ticker : HD.csv, date check : True\n",
            "ticker : PG.csv, date check : True\n",
            "ticker : BCH.csv, date check : True\n",
            "ticker : WMT.csv, date check : True\n",
            "ticker : SNY.csv, date check : True\n",
            "ticker : HSBC.csv, date check : True\n",
            "ticker : AMGN.csv, date check : True\n",
            "ticker : UPS.csv, date check : True\n",
            "ticker : NGG.csv, date check : True\n",
            "ticker : BA.csv, date check : True\n",
            "ticker : MA.csv, date check : True\n",
            "ticker : IEP.csv, date check : True\n",
            "ticker : XOM.csv, date check : True\n",
            "ticker : BSAC.csv, date check : True\n",
            "ticker : DIS.csv, date check : True\n",
            "ticker : BUD.csv, date check : True\n",
            "ticker : PPL.csv, date check : True\n",
            "ticker : ABB.csv, date check : True\n",
            "ticker : CHL.csv, date check : True\n",
            "ticker : AGFS.csv, date check : False\n",
            "ticker : SO.csv, date check : True\n",
            "ticker : GD.csv, date check : True\n",
            "ticker : TSM.csv, date check : True\n",
            "ticker : PM.csv, date check : True\n",
            "ticker : FB.csv, date check : True\n",
            "ticker : DUK.csv, date check : True\n",
            "ticker : CHTR.csv, date check : True\n",
            "ticker : MO.csv, date check : True\n",
            "ticker : PFE.csv, date check : True\n",
            "ticker : MSFT.csv, date check : True\n",
            "ticker : D.csv, date check : True\n",
            "ticker : HON.csv, date check : True\n",
            "ticker : UNH.csv, date check : True\n",
            "ticker : TOT.csv, date check : True\n",
            "ticker : UN.csv, date check : True\n",
            "ticker : V.csv, date check : True\n",
            "ticker : HRG.csv, date check : True\n",
            "ticker : EXC.csv, date check : True\n",
            "ticker : CSCO.csv, date check : True\n",
            "ticker : LMT.csv, date check : True\n",
            "ticker : MCD.csv, date check : True\n",
            "ticker : BAC.csv, date check : True\n",
            "ticker : RDS-B.csv, date check : True\n",
            "ticker : PCG.csv, date check : True\n",
            "ticker : UL.csv, date check : True\n",
            "ticker : C.csv, date check : True\n",
            "ticker : CODI.csv, date check : True\n",
            "ticker : SNP.csv, date check : True\n",
            "ticker : ORCL.csv, date check : True\n",
            "ticker : PEP.csv, date check : True\n",
            "ticker : PCLN.csv, date check : True\n",
            "ticker : MDT.csv, date check : True\n",
            "ticker : TM.csv, date check : True\n",
            "ticker : ABBV.csv, date check : True\n",
            "ticker : MMM.csv, date check : True\n",
            "ticker : JPM.csv, date check : True\n",
            "ticker : REX.csv, date check : True\n",
            "ticker : CMCSA.csv, date check : True\n",
            "ticker : MRK.csv, date check : True\n",
            "87 87\n",
            "fail_cnt : 2\n",
            "ticker : SPY.csv, date check : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2r-44gBpiC0",
        "outputId": "a5185757-a309-4b77-8348-c8a479a18b4e"
      },
      "source": [
        "len(tra_data_X)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdtWB891qCbI"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTOJXSiZWH1T"
      },
      "source": [
        "# layer 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOcNoDEwWOLS"
      },
      "source": [
        "## pytorch module import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_orS3GQnibs"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2fCQwvLnibs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a10ffe0-14dd-457c-f64b-3ab331937a2c"
      },
      "source": [
        "device"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b716kdcpk7Qt"
      },
      "source": [
        "## Hyperparameter setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXiZJn-7kRfc"
      },
      "source": [
        "w = 10 # window size w in {10, 15}\n",
        "beta = 0.01 # market context weight beta in {0.01, 0.1, 1}\n",
        "h = 64 # hidden layer size h in {64, 128}\n",
        "learning_rate = 0.001 # in {0.001, 0.0001}\n",
        "lambda_1 = 1 # selective regularzation lambda = 1\n",
        "drop_rate = 0.15\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHD6RKnenibs"
      },
      "source": [
        "def save_model(model, model_path):\n",
        "    \"\"\"Save model.\"\"\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "\n",
        "def load_model(model, model_path, use_cuda=False):\n",
        "    \"\"\"Load model.\"\"\"\n",
        "    map_location = 'cpu'\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        map_location = 'cuda:0'\n",
        "    model.load_state_dict(torch.load(model_path, map_location))\n",
        "    return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDaNBGP-nibs"
      },
      "source": [
        "## Define model, trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRnXK3IKJVsY",
        "outputId": "3c1774d7-30d6-4903-a7c8-944ca11035e6"
      },
      "source": [
        "#예시\n",
        "# Size: [batch_size, seq_len, input_size]\n",
        "input = torch.randn(12, 384, 768)\n",
        "\n",
        "lstm = nn.LSTM(input_size=768, hidden_size=512, batch_first=True)\n",
        "\n",
        "output, _ = lstm(input)\n",
        "output.size()  # => torch.Size([12, 384, 512])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 384, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOX9UxXdJVp6"
      },
      "source": [
        "numpy_tra_data_X = np.array(tra_data_X)\n",
        "tensor_tra_data_X = torch.Tensor(numpy_tra_data_X)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_7rz9cLJVkd",
        "outputId": "9c30407d-2e37-4082-a4b2-081556a083f3"
      },
      "source": [
        "tensor_tra_data_X.size()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86, 398, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TntHXYfbDH1",
        "outputId": "bc8ba2ef-6fbd-44b1-e793-1c5987207839"
      },
      "source": [
        "feature_size = tensor_tra_data_X.size()[2]\n",
        "feature_size"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5euZGID0YSOQ",
        "outputId": "8664987c-e534-4b54-f80b-176a375b477e"
      },
      "source": [
        "h"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO3Yoz-maxvc"
      },
      "source": [
        "### Feature Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQEkjX_LJVZl"
      },
      "source": [
        "feature_transformation_linear = nn.Linear(feature_size, h)\n",
        "# nn.Linear는 마지막 차원에 feature size만 있으면 그 앞에 어떤 차원이 있던지 마지막 차원 기준으로 linear 층 생성해준다. 너무 좋다"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3a6iz_9YNOS"
      },
      "source": [
        "output = torch.tanh(feature_transformation_linear(tensor_tra_data_X))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKxof27hY0Kp",
        "outputId": "8fc839e3-9256-45fa-898c-b02797b2a6df"
      },
      "source": [
        "output.size()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86, 398, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSFWsFVUf6YT"
      },
      "source": [
        "### window size로 input값 제한"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12Pilomef53j"
      },
      "source": [
        "time_idx = 0\n",
        "train_timesteps = int(tensor_tra_data_X.size()[1]) - w # time_idx의 끝을 의미하고 싶다. -1 해야하는지?\n",
        "Z_tilda = output[:, time_idx:time_idx + w, :]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlPG5OLwgsM7",
        "outputId": "37b49766-be01-41b2-8539-55d3232bc617"
      },
      "source": [
        "output[:, train_timesteps+1:train_timesteps + w + 1, :].size() # -1 하면 사이즈 줄어든다. 이전이 마지막이라는 뜻"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86, 9, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJRi-FLzsJDv",
        "outputId": "170d13fb-8f80-4c13-b631-02c822387dec"
      },
      "source": [
        "len(tickers)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5jFMB3_iain"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbHSDmQJUDcg"
      },
      "source": [
        "# Temporal LSTM\n",
        "# LSTM input size = (batch, seq_len, input_size)\n",
        "# 일단 batch_size는 1로 해보자.\n",
        "\n",
        "# 티커별로 lstm 층 개별로 만들기\n",
        "for i in range(len(tickers)): # 마지막은 index용 lstm\n",
        "    globals()['lstm_{}'.format(i)] = nn.LSTM(input_size = h, hidden_size=h, batch_first=True)\n",
        "\n",
        "\n",
        "# 동적변수 추가법\n",
        "# globals()에는 dict형태로 global 변수가 저장되어 있음\n",
        "# 이를 이용하여 동적 변수 추가 가능 (https://congcoding.tistory.com/55)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BnWJG1DiH4Y",
        "outputId": "43e53bdb-c85f-493d-999f-482f6c1ebaaf"
      },
      "source": [
        "ticker_idx = 0\n",
        "Z_tilda[ticker_idx,:,:].size() # 사이즈 변형해서 넣어야 한다.\n",
        "# LSTM input size = (batch, seq_len, input_size) 으로 batch_size 1 만들어야 함"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPFogO8giQvi",
        "outputId": "78f1350a-e3db-4227-f318-e2521ba562f5"
      },
      "source": [
        "Z_tilda[ticker_idx,:,:].view(1,Z_tilda.size()[1], Z_tilda.size()[2]).size() # shape 변경 완료"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3msNGnAjt-s",
        "outputId": "399200a3-8316-433b-ab3a-cab64d4cc46d"
      },
      "source": [
        "Z_tilda[ticker_idx,:,:].view(1,Z_tilda.size()[1], Z_tilda.size()[2])[0,0,0] - Z_tilda[ticker_idx, 0, 0]\n",
        "# 데이터 검증 완료"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0., grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHnZwrEaj8WR",
        "outputId": "f9d29908-ae32-4e39-fc1d-8f0cd8a23154"
      },
      "source": [
        "z_tilda = Z_tilda[ticker_idx,:,:].view(1,Z_tilda.size()[1], Z_tilda.size()[2])\n",
        "z_tilda.size()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIQavBxHspDv",
        "outputId": "42393344-77f8-460d-8da6-1c179b8eef76"
      },
      "source": [
        "torch.Tensor().new_zeros((1,w,h)).size()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYsjWSTVkY_v"
      },
      "source": [
        "# hidden state ticker별 쌓기\n",
        "H_n = torch.Tensor().new_zeros((len(tickers),w,h)) # +1은 index\n",
        "\n",
        "for ticker_idx in range(len(tickers)):\n",
        "    i = 0\n",
        "    z_tilda = Z_tilda[ticker_idx,:,:].view(1,Z_tilda.size()[1], Z_tilda.size()[2])\n",
        "    lstm_output, (h_n, c_n) = globals()['lstm_{}'.format(ticker_idx)](z_tilda[:,i,:].view(1,1,Z_tilda.size()[2]))\n",
        "    H_n[ticker_idx,0,:] = h_n\n",
        "    for i in range(1,w):\n",
        "        lstm_output, (h_n, c_n) = globals()['lstm_{}'.format(ticker_idx)](z_tilda[:,i,:].view(1,1,Z_tilda.size()[2]), (h_n, c_n))\n",
        "        H_n[ticker_idx,i,:] = h_n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhAS3eRPs2Xh",
        "outputId": "31a95203-55a1-4a66-8e7d-b103bba54f2f"
      },
      "source": [
        "H_n.size()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86, 10, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRHV_yCPkxx9",
        "outputId": "04068331-7f4d-4ab9-dadd-489da436563a"
      },
      "source": [
        "lstm_output.size()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHuKxcf6kocO",
        "outputId": "b40b7018-5a69-473d-e9b0-4996342378ef"
      },
      "source": [
        "h_n.size() # seq_len = 10이므로, h_n 10개 얻고 싶어요... H_n에 모아둠"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3m7zxUIkquj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dd89b58-2ee9-44bd-e206-ea664ccb7745"
      },
      "source": [
        "torch.dot(H_n[0][0], H_n[0][-1])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1407, grad_fn=<DotBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se0ub9Ojs_s-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915b0d3c-4cd1-44a4-e685-e8657b0ea370"
      },
      "source": [
        "torch.matmul(H_n[0], H_n[0][-1])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1407, 0.2134, 0.2514, 0.2711, 0.2815, 0.2868, 0.2896, 0.2911, 0.2915,\n",
              "        0.2925], grad_fn=<MvBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7s24hBT8vax"
      },
      "source": [
        "H_n_dot = torch.Tensor().new_zeros((len(tickers),w)) # 알파_i 계산하기전 ticker별로 dot(h_i, h_T) 계산\n",
        "# size (len(tickers), window_size w)\n",
        "# https://pytorch.org/docs/stable/generated/torch.matmul.html\n",
        "# torch.mul broadcasting 볼수 있음\n",
        "for i in range(len(tickers)):\n",
        "    H_n_dot[i,:] = torch.matmul(H_n[i], H_n[i][-1])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuIoMn-CSPCw",
        "outputId": "6c003d89-f991-4adf-88dd-7a706d7d6ea1"
      },
      "source": [
        "H_n_dot[0] # 데이터 체크 완료"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1407, 0.2134, 0.2514, 0.2711, 0.2815, 0.2868, 0.2896, 0.2911, 0.2915,\n",
              "        0.2925], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tSt6AQlptwk",
        "outputId": "cb9de2bd-ba0f-4705-e98e-87db783a1bcc"
      },
      "source": [
        "H_n_dot.size() # 사이즈 체크 완료"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GokShP06UOhS",
        "outputId": "a78abe0a-cfed-45fe-8286-bb36d606f22b"
      },
      "source": [
        "torch.exp(H_n_dot).size()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3m6AmtbUfVO",
        "outputId": "a6ffb3dd-8413-451f-b7e1-fc4c8be6fe29"
      },
      "source": [
        "torch.exp(H_n_dot)[0]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1510, 1.2379, 1.2858, 1.3115, 1.3251, 1.3321, 1.3358, 1.3379, 1.3384,\n",
              "        1.3398], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRiBCsXEUhw7",
        "outputId": "b6d7f03c-a28d-43d5-fe20-84b114b83686"
      },
      "source": [
        "torch.exp(H_n_dot[0][0]) # 데이터 체크 완료"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.1510, grad_fn=<ExpBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlPsWtM1SZWB"
      },
      "source": [
        "# https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html\n",
        "Alpha = nn.Softmax(dim=1)(torch.exp(H_n_dot))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuI6vRXZ74qs",
        "outputId": "99358884-e74b-43b4-e2af-d97d46d0bef7"
      },
      "source": [
        "H_n[0].size()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIQIboDT74fu",
        "outputId": "be6b88b6-5eaa-452b-84ea-701ac9bc91dd"
      },
      "source": [
        "H_n[0].transpose(-2,-1).size()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ5yHvdOpdak"
      },
      "source": [
        "H_n_tilde = torch.Tensor().new_zeros((len(tickers), h))\n",
        "for i in range(len(tickers)):\n",
        "    H_n_tilde[i,:] = torch.matmul(H_n[i].transpose(-2,-1), Alpha[i])"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUV9T-RUHO11",
        "outputId": "dbb15763-83c3-4ed1-d7b6-d3594fdd19a6"
      },
      "source": [
        "H_n_tilde.size()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDZG83ljIoU0"
      },
      "source": [
        "### Context Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-sdKCA4NS_W",
        "outputId": "83bfae03-04ac-4e07-fa42-9ffa17753f4c"
      },
      "source": [
        "torch.std_mean(H_n_tilde, dim=1, unbiased=False)[0].repeat((h,1)).transpose(-2,-1)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0603, 0.0603, 0.0603,  ..., 0.0603, 0.0603, 0.0603],\n",
              "        [0.0811, 0.0811, 0.0811,  ..., 0.0811, 0.0811, 0.0811],\n",
              "        [0.0716, 0.0716, 0.0716,  ..., 0.0716, 0.0716, 0.0716],\n",
              "        ...,\n",
              "        [0.0662, 0.0662, 0.0662,  ..., 0.0662, 0.0662, 0.0662],\n",
              "        [0.0574, 0.0574, 0.0574,  ..., 0.0574, 0.0574, 0.0574],\n",
              "        [0.0693, 0.0693, 0.0693,  ..., 0.0693, 0.0693, 0.0693]],\n",
              "       grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otu7J3bONcmR",
        "outputId": "040c68e4-5610-4a64-9772-ed0b3df72e7a"
      },
      "source": [
        "H_n_tilde - torch.std_mean(H_n_tilde, dim=1, unbiased=False)[1].repeat((h,1)).transpose(-2,-1)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0862, -0.1012,  0.0868,  ...,  0.0613, -0.0418, -0.0521],\n",
              "        [-0.0706,  0.0229,  0.0906,  ...,  0.1488, -0.0964, -0.0043],\n",
              "        [-0.1369, -0.0038,  0.0513,  ..., -0.0007, -0.0151, -0.0470],\n",
              "        ...,\n",
              "        [ 0.0389, -0.0547, -0.0148,  ...,  0.0521,  0.1303, -0.0836],\n",
              "        [-0.0812,  0.1340,  0.0197,  ...,  0.0328, -0.0388, -0.0739],\n",
              "        [ 0.0893, -0.1552, -0.1130,  ...,  0.0253,  0.0651,  0.0289]],\n",
              "       grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANd6sVTaRHpn",
        "outputId": "c8a8ae81-0742-49b9-b34e-4f78685cbd92"
      },
      "source": [
        "(H_n_tilde - torch.std_mean(H_n_tilde, dim=1, unbiased=False)[1].repeat((h,1)).transpose(-2,-1)).size()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDUzVsknPGKx",
        "outputId": "a9443572-6661-45ab-c1e3-496faf93786d"
      },
      "source": [
        "torch.std_mean(H_n_tilde, dim=1, unbiased=False)[0].size()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXqXEBR0PkBR",
        "outputId": "c78948e3-6298-4acc-af88-79c7462c6227"
      },
      "source": [
        "torch.std_mean(H_n_tilde, dim=1, unbiased=False)[0].repeat((h,1)).transpose(-2,-1).size()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kesEY3T7QG6-",
        "outputId": "a058e195-2e43-45f7-c2bc-7f930e3f6d62"
      },
      "source": [
        "torch.std_mean(H_n_tilde, dim=1, unbiased=False)[0].repeat((h,1)).transpose(-2,-1)[0]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603,\n",
              "        0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603,\n",
              "        0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603,\n",
              "        0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603,\n",
              "        0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603,\n",
              "        0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603,\n",
              "        0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603,\n",
              "        0.0603], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A8YHBxSQmKY",
        "outputId": "1d5a2463-c9b0-4b77-f26d-64a3de4e8705"
      },
      "source": [
        "(H_n_tilde - torch.std_mean(H_n_tilde, dim=1, unbiased=False)[1].repeat((h,1)).transpose(-2,-1))[0]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0862, -0.1012,  0.0868, -0.0103,  0.0044,  0.0034, -0.0407, -0.0322,\n",
              "         0.0024,  0.0856, -0.0944, -0.0330,  0.0052,  0.1654,  0.0771,  0.0179,\n",
              "        -0.1144, -0.0329,  0.0353, -0.0114,  0.0187, -0.0511, -0.0201,  0.0416,\n",
              "        -0.0130,  0.0018, -0.0610, -0.0493, -0.0018,  0.0010, -0.0628, -0.0290,\n",
              "        -0.0625,  0.1016, -0.0940,  0.0363, -0.0358,  0.1271,  0.0417, -0.0523,\n",
              "        -0.0699, -0.0593,  0.1095,  0.0458, -0.0575,  0.0605,  0.0593, -0.0617,\n",
              "         0.0876, -0.0478, -0.0752,  0.0315,  0.0075,  0.0181,  0.0135,  0.0274,\n",
              "         0.0089, -0.0137,  0.0709,  0.0357,  0.0779,  0.0613, -0.0418, -0.0521],\n",
              "       grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv82KUAaQrQz",
        "outputId": "54972894-0196-4afa-c809-f19fa830c16e"
      },
      "source": [
        "(H_n_tilde - torch.std_mean(H_n_tilde, dim=1, unbiased=False)[1].repeat((h,1)).transpose(-2,-1))/torch.std_mean(H_n_tilde, dim=1, unbiased=False)[0].repeat((h,1)).transpose(-2,-1)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.4307, -1.6795,  1.4394,  ...,  1.0177, -0.6938, -0.8637],\n",
              "        [-0.8701,  0.2827,  1.1162,  ...,  1.8336, -1.1882, -0.0530],\n",
              "        [-1.9122, -0.0531,  0.7159,  ..., -0.0093, -0.2106, -0.6568],\n",
              "        ...,\n",
              "        [ 0.5876, -0.8262, -0.2238,  ...,  0.7871,  1.9668, -1.2622],\n",
              "        [-1.4141,  2.3346,  0.3433,  ...,  0.5723, -0.6765, -1.2873],\n",
              "        [ 1.2889, -2.2396, -1.6302,  ...,  0.3653,  0.9396,  0.4169]],\n",
              "       grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0DUOZtRQwTY",
        "outputId": "ee6197e1-b682-4580-b12a-72f2b443c428"
      },
      "source": [
        "((H_n_tilde - torch.std_mean(H_n_tilde, dim=1, unbiased=False)[1].repeat((h,1)).transpose(-2,-1))/torch.std_mean(H_n_tilde, dim=1, unbiased=False)[0].repeat((h,1)).transpose(-2,-1)).size()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kzo3mNEHRnbF"
      },
      "source": [
        "pre_H_c_n = (H_n_tilde - torch.std_mean(H_n_tilde, dim=1, unbiased=False)[1].repeat((h,1)).transpose(-2,-1))/torch.std_mean(H_n_tilde, dim=1, unbiased=False)[0].repeat((h,1)).transpose(-2,-1)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsUzmMswR3Ig",
        "outputId": "1b494365-6c74-4bae-d70d-d55663b304d0"
      },
      "source": [
        "pre_H_c_n.size()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPXJUB1XR9F5"
      },
      "source": [
        "# ticker별로 linear layer 생성\n",
        "for i in range(len(tickers)):\n",
        "    globals()['ContextNormalLinearLayer_{}'.format(i)] = nn.Linear(h, h)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzs21EgfSSFt"
      },
      "source": [
        "H_c_n = torch.Tensor().new_zeros(len(tickers), h)\n",
        "for i in range(len(tickers)):\n",
        "    H_c_n[i,:]= globals()['ContextNormalLinearLayer_{}'.format(i)](pre_H_c_n[i])"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrtQYoSdTjpB",
        "outputId": "cca09662-1d56-4f6e-a4b0-232412ac05c4"
      },
      "source": [
        "H_c_n.size()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn-7zAFtTprn"
      },
      "source": [
        "## 3.3 Multi-Level Context Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czXad761TyJA"
      },
      "source": [
        "H = H_c_n + beta*H_c_n[-1]\n",
        "H = H[:-1] # 마지막 index context vector 제외\n",
        "tickers = tickers[:-1] # 마지막 index ticker 제외"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RBp-kfPwo3W",
        "outputId": "61fa3fc8-d3e6-42bf-951d-08da2e568ee9"
      },
      "source": [
        "H.size()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([85, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ylLb4xPxAZP",
        "outputId": "f6e07468-4331-463e-f9a9-2a6914ddad23"
      },
      "source": [
        "len(tickers)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fvqW9Pq2a-H"
      },
      "source": [
        "## 3.4 Data-Axis Self-Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk1iHV0V5dDH"
      },
      "source": [
        "### Self-Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypeuSJJP2fDo"
      },
      "source": [
        "query_layer = nn.Linear(h, h)\n",
        "key_layer = nn.Linear(h, h)\n",
        "value_layer = nn.Linear(h, h)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1rFWP_ykYNd"
      },
      "source": [
        "Q = query_layer(H)\n",
        "K = key_layer(H)\n",
        "V = value_layer(H)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAL5QRhhkifH"
      },
      "source": [
        "# S 생성\n",
        "S = torch.matmul(Q, K.transpose(-2,-1))\n",
        "S = S/math.sqrt(h)\n",
        "S = nn.Softmax(dim=1)(S)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufc36yE1lvQD"
      },
      "source": [
        "# H_tilda 생성\n",
        "H_tilda = torch.matmul(S,V)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXh5U4165u7v"
      },
      "source": [
        "### Nonlinear Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih3DKX1pltod",
        "outputId": "0b2de9a8-337b-4e33-a2a4-a1d40be2b063"
      },
      "source": [
        "mlp1 = nn.Linear(h, 4h)\n",
        "mlp2 = nn.Linear(4h,h)\n",
        "\n",
        "H_p = H + H_tilda\n",
        "H_p = mlp1(H_p)\n",
        "H_p = nn.ReLU(H_p)\n",
        "\n"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0129, 0.0126, 0.0122,  ..., 0.0104, 0.0136, 0.0134],\n",
              "        [0.0123, 0.0125, 0.0121,  ..., 0.0139, 0.0133, 0.0148],\n",
              "        [0.0134, 0.0155, 0.0122,  ..., 0.0111, 0.0125, 0.0122],\n",
              "        ...,\n",
              "        [0.0111, 0.0126, 0.0118,  ..., 0.0105, 0.0114, 0.0109],\n",
              "        [0.0120, 0.0122, 0.0119,  ..., 0.0113, 0.0114, 0.0110],\n",
              "        [0.0134, 0.0141, 0.0116,  ..., 0.0109, 0.0127, 0.0128]],\n",
              "       grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meOv_OahmLPh",
        "outputId": "556f28e8-e0cd-4301-ad17-b41da703438c"
      },
      "source": [
        "S.size()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([85, 85])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lGWtTgkmMks",
        "outputId": "08d8a1d5-5cf5-4ce2-9d13-0ba8ed086b35"
      },
      "source": [
        "S[0].sum()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEZQMh0ymYcp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIFW9hpclPsF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiP627BiQ53J",
        "outputId": "0cf9f84a-2074-4c44-bfe1-3ff2cf4b81ff"
      },
      "source": [
        "0.0337/0.0547"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6160877513711152"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amgZyNP1RegG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY1AB5b0PPOO"
      },
      "source": [
        "a = torch.Tensor([[1,2,3],[4,5,6]])\n",
        "b = torch.Tensor([[3,3,3],[1,1,1]])"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijNqd24_P_oz",
        "outputId": "a4c69c5b-79cf-4b6f-d34e-10d1b8de5ead"
      },
      "source": [
        "a*b"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 6., 9.],\n",
              "        [4., 5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1t2P0BiP8UJ",
        "outputId": "9cf45197-3561-4846-ae73-d018762ac03f"
      },
      "source": [
        "3*a"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.,  6.,  9.],\n",
              "        [12., 15., 18.]])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu6idSqIPzma",
        "outputId": "ff364aa3-b96b-49c0-c740-bf382069778d"
      },
      "source": [
        "a/b"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3333, 0.6667, 1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHk281iQP0eP",
        "outputId": "bae5a120-1dbd-4167-e574-85cd4705d10b"
      },
      "source": [
        "a*b"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMG8dwCnP5rR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NrLrYpNPeOF",
        "outputId": "b55f5abd-c37e-4fab-841d-094e19138f38"
      },
      "source": [
        "a"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpog23xLPvy3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5muCKc56PN8s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "nqVpTM8kNQLa",
        "outputId": "a48b295f-bb70-473f-cbf5-225545f26238"
      },
      "source": [
        "(H_n_tilde - torch.std_mean(H_n_tilde, dim=1, unbiased=False)[1].repeat((h,1)).transpose(-2,-1))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-80df36c9db0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mH_n_tilde\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_n_tilde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munbiased\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (84) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VYoB2NoNT1K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEHIQNU-kcmr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "b4311a3e-57d4-4bbf-9d2b-2a47cea06cb1"
      },
      "source": [
        "(H_n_tilde - torch.std_mean(H_n_tilde, dim=1, unbiased=False)[0])/torch.std_mean(H_n_tilde, dim=1, unbiased=False)[1].size()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-742be710370a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mH_n_tilde\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_n_tilde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munbiased\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_n_tilde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munbiased\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (84) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxRXWDdSNMoY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nZduplDMUvT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjfSsa0oLC4J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud6pLs57LC1j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKHkMPJSLCye"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooSFcgIcLCv2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMzS8UqXLCtU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6UnBLx3LCnO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyFIN9ZWUDZ8",
        "outputId": "48471989-6ffa-41f8-ed9d-5542fcfb6ea0"
      },
      "source": [
        "train_timesteps = int(tensor_tra_data_X.size()[1])\n",
        "\n",
        "\n",
        "n_iter = 0\n",
        "epoch = 0\n",
        "\n",
        "\n",
        "input = output[ticker_idx,idx : idx + w, :]\n",
        "input.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YAQaBsTUDXD"
      },
      "source": [
        "output_lstm, (h_n, c_n) = lstm(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTT4YSHZUDPd",
        "outputId": "56b5802e-63ad-439f-e857-3e6a6fbd0736"
      },
      "source": [
        "h_n.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 84, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8egDXQQyUDJI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amXFncdrnibt"
      },
      "source": [
        "sample_x = tra_data_X.values\n",
        "sample_y = tra_data_Y.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDe0D21O9JVN"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"encoder in DA_RNN.\"\"\"\n",
        "\n",
        "    def __init__(self, T,\n",
        "                 input_size,\n",
        "                 encoder_num_hidden,\n",
        "                 parallel=False):\n",
        "        \"\"\"Initialize an encoder in DA_RNN.\"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder_num_hidden = encoder_num_hidden\n",
        "        self.input_size = input_size\n",
        "        self.parallel = parallel\n",
        "        self.T = T\n",
        "\n",
        "        # Fig 1. Temporal Attention Mechanism: Encoder is LSTM\n",
        "        self.encoder_lstm = nn.LSTM(\n",
        "            input_size=self.input_size,\n",
        "            hidden_size=self.encoder_num_hidden,\n",
        "            num_layers = 1\n",
        "        )\n",
        "\n",
        "        # Construct Input Attention Mechanism via deterministic attention model\n",
        "        # Eq. 8: W_e[h_{t-1}; s_{t-1}] + U_e * x^k\n",
        "        self.encoder_attn = nn.Linear(\n",
        "            in_features=2 * self.encoder_num_hidden + self.T - 1,\n",
        "            out_features=1\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"forward.\n",
        "\n",
        "        Args:\n",
        "            X: input data\n",
        "\n",
        "        \"\"\"\n",
        "        X_tilde = Variable(X.data.new(\n",
        "            X.size(0), self.T - 1, self.input_size).zero_())\n",
        "        X_encoded = Variable(X.data.new(\n",
        "            X.size(0), self.T - 1, self.encoder_num_hidden).zero_())\n",
        "\n",
        "        # Eq. 8, parameters not in nn.Linear but to be learnt\n",
        "        # v_e = torch.nn.Parameter(data=torch.empty(\n",
        "        #     self.input_size, self.T).uniform_(0, 1), requires_grad=True)\n",
        "        # U_e = torch.nn.Parameter(data=torch.empty(\n",
        "        #     self.T, self.T).uniform_(0, 1), requires_grad=True)\n",
        "\n",
        "        # h_n, s_n: initial states with dimention hidden_size\n",
        "        h_n = self._init_states(X)\n",
        "        s_n = self._init_states(X)\n",
        "\n",
        "        for t in range(self.T - 1):\n",
        "            # batch_size * input_size * (2 * hidden_size + T - 1)\n",
        "            x = torch.cat((h_n.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
        "                           s_n.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
        "                           X.permute(0, 2, 1)), dim=2)\n",
        "\n",
        "            x = self.encoder_attn(\n",
        "                x.view(-1, self.encoder_num_hidden * 2 + self.T - 1))\n",
        "\n",
        "            # get weights by softmax\n",
        "            alpha = F.softmax(x.view(-1, self.input_size))\n",
        "\n",
        "            # get new input for LSTM\n",
        "            x_tilde = torch.mul(alpha, X[:, t, :])\n",
        "\n",
        "            # Fix the warning about non-contiguous memory\n",
        "            # https://discuss.pytorch.org/t/dataparallel-issue-with-flatten-parameter/8282\n",
        "            self.encoder_lstm.flatten_parameters()\n",
        "\n",
        "            # encoder LSTM\n",
        "            _, final_state = self.encoder_lstm(x_tilde.unsqueeze(0), (h_n, s_n))\n",
        "            h_n = final_state[0]\n",
        "            s_n = final_state[1]\n",
        "\n",
        "            X_tilde[:, t, :] = x_tilde\n",
        "            X_encoded[:, t, :] = h_n\n",
        "\n",
        "        return X_tilde, X_encoded\n",
        "\n",
        "    def _init_states(self, X):\n",
        "        \"\"\"Initialize all 0 hidden states and cell states for encoder.\n",
        "\n",
        "        Args:\n",
        "            X\n",
        "\n",
        "        Returns:\n",
        "            initial_hidden_states\n",
        "        \"\"\"\n",
        "        # https://pytorch.org/docs/master/nn.html?#lstm\n",
        "        return Variable(X.data.new(1, X.size(0), self.encoder_num_hidden).zero_())\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"decoder in DA_RNN.\"\"\"\n",
        "\n",
        "    def __init__(self, T, decoder_num_hidden, encoder_num_hidden):\n",
        "        \"\"\"Initialize a decoder in DA_RNN.\"\"\"\n",
        "        super(Decoder, self).__init__()\n",
        "        self.decoder_num_hidden = decoder_num_hidden\n",
        "        self.encoder_num_hidden = encoder_num_hidden\n",
        "        self.T = T\n",
        "\n",
        "        self.attn_layer = nn.Sequential(\n",
        "            nn.Linear(2 * decoder_num_hidden + encoder_num_hidden, encoder_num_hidden),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(encoder_num_hidden, 1)\n",
        "        )\n",
        "        self.lstm_layer = nn.LSTM(\n",
        "            input_size=1,\n",
        "            hidden_size=decoder_num_hidden\n",
        "        )\n",
        "        self.fc = nn.Linear(encoder_num_hidden + 1, 1)\n",
        "        self.fc_final = nn.Linear(decoder_num_hidden + encoder_num_hidden, 1)\n",
        "\n",
        "        self.fc.weight.data.normal_()\n",
        "\n",
        "    def forward(self, X_encoded, y_prev):\n",
        "        \"\"\"forward.\"\"\"\n",
        "        d_n = self._init_states(X_encoded)\n",
        "        c_n = self._init_states(X_encoded)\n",
        "\n",
        "        for t in range(self.T - 1):\n",
        "\n",
        "            x = torch.cat((d_n.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n",
        "                           c_n.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n",
        "                           X_encoded), dim=2)\n",
        "\n",
        "            beta = F.softmax(self.attn_layer(\n",
        "                x.view(-1, 2 * self.decoder_num_hidden + self.encoder_num_hidden)).view(-1, self.T - 1))\n",
        "\n",
        "            # Eqn. 14: compute context vector\n",
        "            # batch_size * encoder_hidden_size\n",
        "            context = torch.bmm(beta.unsqueeze(1), X_encoded)[:, 0, :]\n",
        "            if t < self.T - 1:\n",
        "                # Eqn. 15\n",
        "                # batch_size * 1\n",
        "                y_tilde = self.fc(\n",
        "                    torch.cat((context, y_prev[:, t].unsqueeze(1)), dim=1))\n",
        "\n",
        "                # Eqn. 16: LSTM\n",
        "                self.lstm_layer.flatten_parameters()\n",
        "                _, final_states = self.lstm_layer(\n",
        "                    y_tilde.unsqueeze(0), (d_n, c_n))\n",
        "\n",
        "                d_n = final_states[0]  # 1 * batch_size * decoder_num_hidden\n",
        "                c_n = final_states[1]  # 1 * batch_size * decoder_num_hidden\n",
        "\n",
        "        # Eqn. 22: final output\n",
        "        y_pred = self.fc_final(torch.cat((d_n[0], context), dim=1))\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def _init_states(self, X):\n",
        "        \"\"\"Initialize all 0 hidden states and cell states for encoder.\n",
        "\n",
        "        Args:\n",
        "            X\n",
        "        Returns:\n",
        "            initial_hidden_states\n",
        "\n",
        "        \"\"\"\n",
        "        # hidden state and cell state [num_layers*num_directions, batch_size, hidden_size]\n",
        "        # https://pytorch.org/docs/master/nn.html?#lstm\n",
        "        return Variable(X.data.new(1, X.size(0), self.decoder_num_hidden).zero_())\n",
        "\n",
        "\n",
        "class DA_rnn(nn.Module):\n",
        "    \"\"\"da_rnn.\"\"\"\n",
        "\n",
        "    def __init__(self, X, y, T,\n",
        "                 encoder_num_hidden,\n",
        "                 decoder_num_hidden,\n",
        "                 batch_size,\n",
        "                 learning_rate,\n",
        "                 epochs,\n",
        "                 parallel=False):\n",
        "        \"\"\"da_rnn initialization.\"\"\"\n",
        "        super(DA_rnn, self).__init__()\n",
        "        self.encoder_num_hidden = encoder_num_hidden\n",
        "        self.decoder_num_hidden = decoder_num_hidden\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.parallel = parallel\n",
        "        self.shuffle = False\n",
        "        self.epochs = epochs\n",
        "        self.T = T\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        print(\"==> Use accelerator: \", self.device)\n",
        "\n",
        "        self.Encoder = Encoder(input_size=X.shape[1],\n",
        "                               encoder_num_hidden=encoder_num_hidden,\n",
        "                               T=T).to(self.device)\n",
        "        self.Decoder = Decoder(encoder_num_hidden=encoder_num_hidden,\n",
        "                               decoder_num_hidden=decoder_num_hidden,\n",
        "                               T=T).to(self.device)\n",
        "\n",
        "        # Loss function\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        if self.parallel:\n",
        "            self.encoder = nn.DataParallel(self.encoder)\n",
        "            self.decoder = nn.DataParallel(self.decoder)\n",
        "\n",
        "        self.encoder_optimizer = optim.Adam(params=filter(lambda p: p.requires_grad,\n",
        "                                                          self.Encoder.parameters()),\n",
        "                                            lr=self.learning_rate)\n",
        "        self.decoder_optimizer = optim.Adam(params=filter(lambda p: p.requires_grad,\n",
        "                                                          self.Decoder.parameters()),\n",
        "                                            lr=self.learning_rate)\n",
        "\n",
        "        # Training set\n",
        "        self.train_timesteps = int(self.X.shape[0] * 0.7)\n",
        "        self.y = self.y - np.mean(self.y[:self.train_timesteps])\n",
        "        self.input_size = self.X.shape[1]\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"training process.\"\"\"\n",
        "        iter_per_epoch = int(np.ceil(self.train_timesteps * 1. / self.batch_size))\n",
        "        self.iter_losses = np.zeros(self.epochs * iter_per_epoch)\n",
        "        self.epoch_losses = np.zeros(self.epochs)\n",
        "\n",
        "        n_iter = 0\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            if self.shuffle:\n",
        "                ref_idx = np.random.permutation(self.train_timesteps - self.T)\n",
        "            else:\n",
        "                ref_idx = np.array(range(self.train_timesteps - self.T))\n",
        "\n",
        "            idx = 0\n",
        "\n",
        "            while (idx < self.train_timesteps):\n",
        "                # get the indices of X_train\n",
        "                indices = ref_idx[idx:(idx + self.batch_size)]\n",
        "                # x = np.zeros((self.T - 1, len(indices), self.input_size))\n",
        "                x = np.zeros((len(indices), self.T - 1, self.input_size))\n",
        "                y_prev = np.zeros((len(indices), self.T - 1))\n",
        "                y_gt = self.y[indices + self.T]\n",
        "\n",
        "                # format x into 3D tensor\n",
        "                for bs in range(len(indices)):\n",
        "                    x[bs, :, :] = self.X[indices[bs]:(indices[bs] + self.T - 1), :]\n",
        "                    y_prev[bs, :] = self.y[indices[bs]: (indices[bs] + self.T - 1)]\n",
        "\n",
        "                loss = self.train_forward(x, y_prev, y_gt)\n",
        "                self.iter_losses[int(epoch * iter_per_epoch + idx / self.batch_size)] = loss\n",
        "\n",
        "                idx += self.batch_size\n",
        "                n_iter += 1\n",
        "\n",
        "                if n_iter % 10000 == 0 and n_iter != 0:\n",
        "                    for param_group in self.encoder_optimizer.param_groups:\n",
        "                        param_group['lr'] = param_group['lr'] * 0.9\n",
        "                    for param_group in self.decoder_optimizer.param_groups:\n",
        "                        param_group['lr'] = param_group['lr'] * 0.9\n",
        "\n",
        "                self.epoch_losses[epoch] = np.mean(self.iter_losses[range(\n",
        "                    epoch * iter_per_epoch, (epoch + 1) * iter_per_epoch)])\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                print(\"Epochs: \", epoch, \" Iterations: \", n_iter,\n",
        "                      \" Loss: \", self.epoch_losses[epoch])\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                y_train_pred = self.test(on_train=True)\n",
        "                y_test_pred = self.test(on_train=False)\n",
        "                y_pred = np.concatenate((y_train_pred, y_test_pred))\n",
        "                plt.ioff()\n",
        "                plt.figure()\n",
        "                plt.plot(range(1, 1 + len(self.y)), self.y, label=\"True\")\n",
        "                plt.plot(range(self.T, len(y_train_pred) + self.T),\n",
        "                         y_train_pred, label='Predicted - Train')\n",
        "                plt.plot(range(self.T + len(y_train_pred), len(self.y) + 1),\n",
        "                         y_test_pred, label='Predicted - Test')\n",
        "                plt.legend(loc='upper left')\n",
        "                plt.show()\n",
        "\n",
        "            # # Save files in last iterations\n",
        "            # if epoch == self.epochs - 1:\n",
        "            #     np.savetxt('../loss.txt', np.array(self.epoch_losses), delimiter=',')\n",
        "            #     np.savetxt('../y_pred.txt',\n",
        "            #                np.array(self.y_pred), delimiter=',')\n",
        "            #     np.savetxt('../y_true.txt',\n",
        "            #                np.array(self.y_true), delimiter=',')\n",
        "\n",
        "    def train_forward(self, X, y_prev, y_gt):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            X:\n",
        "            y_prev:\n",
        "            y_gt: Ground truth label\n",
        "\n",
        "        \"\"\"\n",
        "        # zero gradients\n",
        "        self.encoder_optimizer.zero_grad()\n",
        "        self.decoder_optimizer.zero_grad()\n",
        "\n",
        "        input_weighted, input_encoded = self.Encoder(\n",
        "            Variable(torch.from_numpy(X).type(torch.FloatTensor).to(self.device)))\n",
        "        y_pred = self.Decoder(input_encoded, Variable(\n",
        "            torch.from_numpy(y_prev).type(torch.FloatTensor).to(self.device)))\n",
        "\n",
        "        y_true = Variable(torch.from_numpy(\n",
        "            y_gt).type(torch.FloatTensor).to(self.device))\n",
        "\n",
        "        y_true = y_true.view(-1, 1)\n",
        "        loss = self.criterion(y_pred, y_true)\n",
        "        loss.backward()\n",
        "\n",
        "        self.encoder_optimizer.step()\n",
        "        self.decoder_optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "\n",
        "    def test(self, on_train=False):\n",
        "        \"\"\"test.\"\"\"\n",
        "\n",
        "        if on_train:\n",
        "            y_pred = np.zeros(self.train_timesteps - self.T + 1)\n",
        "        else:\n",
        "            y_pred = np.zeros(self.X.shape[0] - self.train_timesteps)\n",
        "\n",
        "        i = 0\n",
        "        while i < len(y_pred):\n",
        "            batch_idx = np.array(range(len(y_pred)))[i: (i + self.batch_size)]\n",
        "            X = np.zeros((len(batch_idx), self.T - 1, self.X.shape[1]))\n",
        "            y_history = np.zeros((len(batch_idx), self.T - 1))\n",
        "\n",
        "            for j in range(len(batch_idx)):\n",
        "                if on_train:\n",
        "                    X[j, :, :] = self.X[range(\n",
        "                        batch_idx[j], batch_idx[j] + self.T - 1), :]\n",
        "                    y_history[j, :] = self.y[range(\n",
        "                        batch_idx[j], batch_idx[j] + self.T - 1)]\n",
        "                else:\n",
        "                    X[j, :, :] = self.X[range(\n",
        "                        batch_idx[j] + self.train_timesteps - self.T, batch_idx[j] + self.train_timesteps - 1), :]\n",
        "                    y_history[j, :] = self.y[range(\n",
        "                        batch_idx[j] + self.train_timesteps - self.T, batch_idx[j] + self.train_timesteps - 1)]\n",
        "\n",
        "            y_history = Variable(torch.from_numpy(\n",
        "                y_history).type(torch.FloatTensor).to(self.device))\n",
        "            _, input_encoded = self.Encoder(\n",
        "                Variable(torch.from_numpy(X).type(torch.FloatTensor).to(self.device)))\n",
        "            y_pred[i:(i + self.batch_size)] = self.Decoder(input_encoded,\n",
        "                                                           y_history).cpu().data.numpy()[:, 0]\n",
        "            i += self.batch_size\n",
        "\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRIWS9fg9TeN"
      },
      "source": [
        "X = sample_x\n",
        "y= sample_y\n",
        "\n",
        "batchsize = 128\n",
        "nhidden_encoder = 128\n",
        "nhidden_decoder = 128\n",
        "ntimestep = 10\n",
        "lr = 0.001\n",
        "epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "3tVycwoF9fS1",
        "outputId": "c15c7a40-9484-4b51-d440-218494fcfc56"
      },
      "source": [
        "# Initialize model\n",
        "print(\"==> Initialize DA-RNN model ...\")\n",
        "model = DA_rnn(\n",
        "    X,\n",
        "    y,\n",
        "    ntimestep,\n",
        "    nhidden_encoder,\n",
        "    nhidden_decoder,\n",
        "    batchsize,\n",
        "    lr,\n",
        "    epochs\n",
        ")\n",
        "\n",
        "# Train\n",
        "print(\"==> Start training ...\")\n",
        "model.train()\n",
        "\n",
        "# Prediction\n",
        "y_pred = model.test()\n",
        "\n",
        "fig1 = plt.figure()\n",
        "plt.semilogy(range(len(model.iter_losses)), model.iter_losses)\n",
        "plt.savefig(\"1.png\")\n",
        "plt.close(fig1)\n",
        "\n",
        "fig2 = plt.figure()\n",
        "plt.semilogy(range(len(model.epoch_losses)), model.epoch_losses)\n",
        "plt.savefig(\"2.png\")\n",
        "plt.close(fig2)\n",
        "\n",
        "fig3 = plt.figure()\n",
        "plt.plot(y_pred, label='Predicted')\n",
        "plt.plot(model.y[model.train_timesteps:], label=\"True\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.savefig(\"3.png\")\n",
        "plt.close(fig3)\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Initialize DA-RNN model ...\n",
            "==> Use accelerator:  cpu\n",
            "==> Start training ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:129: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-28b75cba9f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==> Start training ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-9effa83eda85>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0my_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0miter_per_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-9effa83eda85>\u001b[0m in \u001b[0;36mtrain_forward\u001b[0;34m(self, X, y_prev, y_gt)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m-> 1121\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: 1D target tensor expected, multi-target not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwMg4lxM9jWF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}